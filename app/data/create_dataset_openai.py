import os
from openai import OpenAI
from typing import Literal
import json
import time
import random
from pydantic import BaseModel


class Dialog(BaseModel):
    sys: list[str]
    usr: list[str]


class SlotValue(BaseModel):
    domain: str
    slot: str
    value: str


class TurnData(BaseModel):
    ID: str
    turn_id: int
    domains: list[str]
    dialog: Dialog
    slot_values: list[SlotValue]
    turn_slot_values: list[SlotValue]
    last_slot_values: list[SlotValue]


domain_slot_file = "app/config/domain_slots.json"
output_file = "app/data/gpt4o_dataset.json"
num_examples = 240

with open(domain_slot_file, "r") as f:
    DOMAIN_SLOTS = json.load(f)

DOMAIN_TYPES = Literal[tuple(DOMAIN_SLOTS.keys())]
SLOT_TYPES = {domain: Literal[tuple(slots)] for domain, slots in DOMAIN_SLOTS.items()}


last_turn_prompt = (
    "\n\ní˜„ì¬ëŠ” ëŒ€í™”ì˜ ë§ˆì§€ë§‰ í„´ì…ë‹ˆë‹¤. ì‚¬ìš©ìëŠ” ë°˜ë“œì‹œ ëŒ€í™”ë¥¼ ë§ˆë¬´ë¦¬í•˜ëŠ” ë‚´ìš©ì„ ë°œí™”ì— í¬í•¨ì‹œì¼œì•¼ í•©ë‹ˆë‹¤."
    "\në§ˆì§€ë§‰ ë°œí™” ì˜ˆì‹œ:"
    "\n- '1. ê·¸ë˜, ì´ì œ ë‹¤ ëì–´. ê³ ë§ˆì›Œ.'"
    "\n- '2. ê·¸ê²Œ ë‹¤ì•¼. ë„ì™€ì¤˜ì„œ ê³ ë§ˆì›Œ.'"
    "\n- '3. ê´œì°®ì•„. ë” í•„ìš”í•œ ê±´ ì—†ì–´.'"
    "\n- '4.ê·¸ë˜, ë‹¤ í–ˆì–´. ìˆ˜ê³ í–ˆì–´.'"
    "\n- '5. ì´ì œ ê·¸ë§Œ.'"
)


def create_system_prompt(
    domains: list[str], previous_turn: dict = None, is_last_turn: bool = False
):
    available_slots = {domain: DOMAIN_SLOTS[domain] for domain in domains}
    slot_constraints = {}

    for domain, slots in available_slots.items():
        slot_constraints[domain] = {}
        for slot, values in slots.items():
            if isinstance(values, dict) and values.get("type") == "range":
                slot_constraints[domain][slot] = f"{values['min']} ~ {values['max']}"
            elif isinstance(values, list):
                slot_constraints[domain][slot] = ", ".join(values)

    base_prompt = (
        "ë‹¹ì‹ ì€ ë‹¤ì¤‘ ë„ë©”ì¸ ì‘ì—… ì§€í–¥ ëŒ€í™”ë¥¼ ìƒì„±í•˜ëŠ” AIì…ë‹ˆë‹¤. "
        "ê° ë„ë©”ì¸(ê°€ì „ì œí’ˆ)ì— ëŒ€í•´ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì™€ ì ì ˆí•œ ìŠ¬ë¡¯-ê°’ ìŒì„ ìƒì„±í•˜ì„¸ìš”. "
        "ëª¨ë“  ëŒ€í™”ëŠ” ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ìƒì„±í•´ì•¼ í•˜ë©°, ì‹¤ì œ ì‚¬ëŒë“¤ì´ ëŒ€í™”í•˜ëŠ” ê²ƒì²˜ëŸ¼ ìì—°ìŠ¤ëŸ¬ì›Œì•¼ í•©ë‹ˆë‹¤. "
        "ì‹œìŠ¤í…œê³¼ ì‚¬ìš©ì ê°„ì˜ ëŒ€í™”ê°€ ìì—°ìŠ¤ëŸ¬ìš´ í•œêµ­ì–´ë¡œ ì´ë£¨ì–´ì ¸ì•¼ í•©ë‹ˆë‹¤."
        "ìŠ¤í‚¤ë§ˆ ì„¤ëª…ì…ë‹ˆë‹¤:\n"
        "- ID: ëŒ€í™” ì‹ë³„ì (ì˜ˆ: 'ALIVE0000')\n"
        "- turn_id: í˜„ì¬ ëŒ€í™”ì˜ í„´ ë²ˆí˜¸ (0ë¶€í„° ì‹œì‘)\n"
        "- domains: í˜„ì¬ ëŒ€í™”ì— ì°¸ì—¬í•˜ëŠ” ê°€ì „ì œí’ˆ ëª©ë¡\n"
        "- dialog: ëŒ€í™” ë‚´ìš©\n"
        "  - sys: ì‹œìŠ¤í…œ ë°œí™” ëª©ë¡\n"
        "  - usr: ì‚¬ìš©ì ë°œí™” ëª©ë¡\n"
        "- slot_values: ëŒ€í™” ì‹œì‘ë¶€í„° í˜„ì¬ê¹Œì§€ ëˆ„ì ëœ ëª¨ë“  ìŠ¬ë¡¯ ê°’ë“¤\n"
        "- turn_slot_values: í˜„ì¬ í„´ì—ì„œ ë³€ê²½ëœ ìŠ¬ë¡¯ ê°’ë“¤\n"
        "- last_slot_values: ì´ì „ í„´ì—ì„œ ë³€ê²½ëœ ìŠ¬ë¡¯ ê°’ë“¤\n\n"
        "ìŠ¬ë¡¯ ê°’ ê¸°ë¡ ì‹œ ì£¼ì˜ì‚¬í•­:\n"
        "1. turn_slot_valuesëŠ” í˜„ì¬ í„´ì—ì„œ ì‚¬ìš©ìì˜ ë°œí™”ì— ì˜í•´ ë³€ê²½ëœ ê°’ë§Œ í¬í•¨\n"
        "2. ì´ì „ í„´ì˜ ê°’ì€ last_slot_valuesì— ìë™ìœ¼ë¡œ í¬í•¨ë¨\n"
        "3. slot_valuesëŠ” last_slot_valuesì™€ turn_slot_valuesì˜ ëˆ„ì  ë¦¬ìŠ¤íŠ¸\n\n"
        "\n\nëŒ€í™” ê·œì¹™:"
        "\n1. ì²« í„´(turn_id=0)ì—ì„œë§Œ ì‹œìŠ¤í…œ ì‘ë‹µì´ ë¹ˆ ë¬¸ìì—´('')ì´ì–´ì•¼ í•©ë‹ˆë‹¤. ê·¸ ì™¸ì˜ í„´ì—ì„œëŠ” ì‹œìŠ¤í…œì´ ì‚¬ìš©ìì˜ ìš”ì²­ì— ëŒ€í•´ ìƒì„¸í•˜ê³  ì¹œì ˆí•œ ì‘ë‹µì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤."
        "\n2. ì‹œìŠ¤í…œì€ ë°˜ë“œì‹œ ì¡´ëŒ“ë§ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤."
        "\n3. ì‚¬ìš©ìëŠ” ë°˜ë“œì‹œ ë°˜ë§(informal speech)ì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤."
        "\n4. ì‚¬ìš©ìì˜ ë°œí™”ëŠ” ë‹¨ìˆœí•œ ëª…ë ¹ì´ ì•„ë‹Œ, ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ì²´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
        f"í˜„ì¬ ëŒ€í™”ì—ì„œ ë‹¤ë£¨ëŠ” ë„ë©”ì¸ê³¼ ì‚¬ìš© ê°€ëŠ¥í•œ ìŠ¬ë¡¯ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤: "
        f"{json.dumps(slot_constraints, indent=2, ensure_ascii=False)}. "
    )

    if is_last_turn:
        base_prompt += last_turn_prompt

    if previous_turn:
        context = (
            "\nì´ì „ í„´ì˜ ëŒ€í™” ë‚´ìš©ì…ë‹ˆë‹¤:"
            f"\nì‹œìŠ¤í…œ: {previous_turn['dialog']['sys'][-1]}"
            f"\nì‚¬ìš©ì: {previous_turn['dialog']['usr'][-1]}"
            f"\nì´ì „ í„´ì˜ ìŠ¬ë¡¯ ê°’: {json.dumps(previous_turn['turn_slot_values'], indent=2, ensure_ascii=False)}"
            f"\ní˜„ì¬ ëŒ€í™”ì—ì„œ ë‹¤ë¤„ì•¼ í•  ë„ë©”ì¸: {', '.join(domains)}"
        )
        base_prompt += context

    return base_prompt


def generate_dialog(client: OpenAI, num_examples=10):
    dialogues = []

    for dialog_idx in range(0, num_examples):
        num_domains = random.randint(1, 2)
        selected_domains = random.sample(list(DOMAIN_SLOTS.keys()), num_domains)

        turns_per_dialog = random.randint(3, 5)

        current_dialog = []

        for turn_idx in range(0, turns_per_dialog):
            start_time = time.time()
            previous_turn = current_dialog[-1] if current_dialog else None
            is_last_turn = turn_idx == turns_per_dialog - 1
            system_prompt = create_system_prompt(
                selected_domains, previous_turn, is_last_turn
            )

            completion = client.beta.chat.completions.parse(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {
                        "role": "user",
                        "content": (
                            f"ë‹¤ìŒ ë„ë©”ì¸ì— ëŒ€í•œ ëŒ€í™”ì˜ í„´ {turn_idx}ë¥¼ ìƒì„±í•˜ì„¸ìš”: {selected_domains}. "
                            "ì´ì „ ëŒ€í™” ë¬¸ë§¥ì„ ê³ ë ¤í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì„¸ìš”."
                            f"{'í˜„ì¬ê°€ ì²« ë²ˆì§¸ í„´ì´ë¯€ë¡œ, ì‹œìŠ¤í…œì€ ë¹ˆ ë¬¸ìì—´('')ë¡œ ì‘ë‹µí•´ì•¼ í•©ë‹ˆë‹¤.' if is_last_turn else ''}"
                            f"{last_turn_prompt if is_last_turn else ''}"
                        ),
                    },
                ],
                max_tokens=2000,
                temperature=0.7,
                response_format=TurnData,
            )
            if completion:
                turn_data = completion.choices[0].message.parsed

                if turn_idx == 0:
                    turn_data.dialog.sys = [""]

                current_dialog.append(turn_data.model_dump())
                elapsed_time = time.time() - start_time
                print(
                    f"âœ… [{dialog_idx + 1}/{num_examples}] ëŒ€í™” {turn_idx + 1}/{turns_per_dialog} ìƒì„± ì™„ë£Œ: "
                    f"{selected_domains} (â±ï¸ {elapsed_time:.2f}ì´ˆ)"
                )
        dialogues.extend(current_dialog)
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(dialogues, f, indent=2, ensure_ascii=False)


def main():
    api_key = os.getenv("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("í™˜ê²½ ë³€ìˆ˜ 'OPENAI_API_KEY'ë¥¼ ì„¤ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
    client = OpenAI(api_key=api_key)
    try:
        print("=" * 100)
        print("ğŸ’¾ ë°ì´í„°ë¥¼ ì €ì¥ ì¤‘")
        start_time = time.time()
        generate_dialog(client, num_examples=num_examples)
        elapsed_time = time.time() - start_time
        print(f"ğŸ‰ ë°ì´í„° ìƒì„± ì™„ë£Œ: ì´ ê±¸ë¦° ì‹œê°„ : {elapsed_time:.2f}ì´ˆ")
        print("=" * 100)
    except Exception as e:
        print(f"ë°ì´í„° ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")


if __name__ == "__main__":
    main()
